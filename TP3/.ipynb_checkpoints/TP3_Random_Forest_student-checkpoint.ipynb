{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T13:40:30.389329Z",
     "start_time": "2021-11-23T13:40:27.788833Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font  style=\"font-size: 4rem; color: #1abc9c\"> Model Combination : </font> \n",
    "<font  style=\"font-size: 4rem; color: #1abc9c\"> Random Forests, Adaboost </font>\n",
    "\n",
    "In Scikit-learn, the Random Forests methods are implemented via the <code>RandomForestClassifier</code> and <code>RandomForestCRegressor</code> class. Main parameters are:\n",
    "\n",
    "    n_estimators: the number of trees in the forest.\n",
    "\n",
    "    max_features : the number of attributes randomly drawn.\n",
    "\n",
    "    oob_score : boolean. Estimate or not the generalization error OOB (Out of Bag).\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "# <font color=\"#1E90FF\">Exercise 1. Random Forest exploration</font>\n",
    "\n",
    "\n",
    "In this exercise, we will take in hand the implementation of the RF. The dataset is based on \"Bank Marketing\" UCI dataset. The binary classification goal is to predict if the client will subscribe a bank term deposit (variable y).\n",
    "\n",
    "Input variables:\n",
    "\n",
    "    1 - age (numeric)\n",
    "    2 - job : type of job (categorical: \"admin.\",\"bluecollar\",\"entrepreneur\",\"housemaid\",\"management\",\"retired\",\"self-employed\",\"services\",\"student\",\"technician\",\"unemployed\",\"unknown\")\n",
    "    3 - education (categorical: \"basic.4y\",\"basic.6y\",\"basic.9y\",\"high.school\",\"illiterate\",\"professional.course\",\"university.degree\",\"unknown\")\n",
    "    4 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "    5 - cons.price.idx: consumer price index - monthly indicator (numeric) \n",
    "    6 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)     \n",
    "    7 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "    8 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "\n",
    "## <font color=\"#9400D3\">1. Data processing </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "bank_data = pd.read_csv('./data/bank-additional-modified.csv', sep=';')\n",
    "bank_data['y'] = bank_data['y'].map({'no':0,'yes':1})\n",
    "print(pd.value_counts(bank_data.y))\n",
    "bank_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 1:**</font> Describe the dataset : number of samples, features, classes, class distribution\n",
    "\n",
    "\n",
    "Attributes should be numeric. We employ the <code>OrdinalEncoder</code> preprocessing method to transform the categorical attributes.\n",
    "\n",
    "<font color=\"red\">**Question 2:**</font> Explain the effect of this encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "oenc=OrdinalEncoder()\n",
    "bank_data[[\"job\",\"education\"]] = oenc.fit_transform(bank_data[[\"job\",\"education\"]])\n",
    "bank_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#9400D3\">2. RF classifier </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset split into train/test set\n",
    "bank_train, bank_test = train_test_split(bank_data, test_size = 0.3, random_state = 50)\n",
    "\n",
    "# Learn a RF classifier\n",
    "r_f = RandomForestClassifier(n_estimators=15, random_state=0, oob_score=True)\n",
    "r_f.fit(bank_train.iloc[:,:-1],bank_train.y) \n",
    "\n",
    "\n",
    "# Feature importance\n",
    "# Create a series containing feature importances from the model and feature names from the training data\n",
    "feature_importances = pd.Series(r_f.feature_importances_, index=bank_train.columns[:-1]).sort_values(ascending=False)\n",
    "\n",
    "# Plot a simple bar chart\n",
    "feature_importances.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 3:**</font> How many trees are used in the ensemble?\n",
    "\n",
    "<font color=\"red\">**Question 4:**</font> How many features are consider when looking for the best split?\n",
    "\n",
    "<font color=\"red\">**Question 5:**</font> Recall how the importance of variables is determined.\n",
    "\n",
    "<font color=\"blue\">**Todo:**</font> Compute the prediction score of this random forest on the train set (function <code>score()</code>) and on the OOB samples (**attribute** <code>oob_score_</code>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - compute prediction scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 6:**</font> \n",
    "- What represents the OOB score?\n",
    "- Compare with the real (generalization) error estimated on the test set.\n",
    "\n",
    "## <font color=\"#9400D3\">3. Comparison with a decision tree </font>\n",
    "\n",
    "<font color=\"blue\">**Todo:**</font> Fit a decision tree classifier, and compute the real accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Fit a decision tree classifier, and compute the real accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#1E90FF\">Exercise 2. RF on Handwritten digits</font>\n",
    "Similarly to Decision Trees notebook, we will first apply random forest to the raw images, and then try to improve the performance using HOG representations of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T13:09:47.669168Z",
     "start_time": "2021-11-23T13:09:47.489235Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist = pd.read_csv('./data/cp_sample.csv', sep=';')\n",
    "mnist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T13:10:46.105731Z",
     "start_time": "2021-11-23T13:10:46.068184Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset split into train/test set\n",
    "data_train, data_test = train_test_split(mnist, test_size = 0.3, random_state = 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#9400D3\">1. Basic RF</font>\n",
    "\n",
    "<font color=\"blue\">**Todo:**</font> learn a RandomForest with 10 trees, enabling the use of out-of-bag samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T13:10:52.107853Z",
     "start_time": "2021-11-23T13:10:52.000890Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO - learn a RandomForest with 10 trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T13:19:31.575898Z",
     "start_time": "2021-11-23T13:19:31.517688Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO - compute RF empirical, OOB and real errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#9400D3\">2. Tuning the number of trees</font>\n",
    "\n",
    "Try now different random forests (by considering different number of trees) and select the most appropriated one.\n",
    "Use the OOB sample estimates which allows the RandomForestClassifier to be fit and validated whilst being trained.\n",
    "Plot the OOB **error** as a function of the number of trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Ntrees=[...]\n",
    "# train_scores, oob_scores = np.zeros(len(Ntrees)), np.zeros(len(Ntrees))\n",
    "\n",
    "#for count,n_tree in enumerate(Ntrees):\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - Plot the OOB error as a function of the number of trees.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 1:**</font> \n",
    "- What is the best number of trees for this dataset?\n",
    "- What is the estimation of the generalization error of the selected random forest ?\n",
    "- Compare with the previous (basic) RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T13:37:37.222681Z",
     "start_time": "2021-11-23T13:37:36.848963Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO - evaluate best RF classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#9400D3\">3. Using HOG features</font>\n",
    "\n",
    "You will now use HOG representations of images to try to improve the classification performance.\n",
    "\n",
    "We compute the new training and test set with HOG representations with 8 orientations and cells of $14\\times14$ pixels (you can change after)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T13:39:19.561680Z",
     "start_time": "2021-11-23T13:39:19.541406Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_hog(row, ori, cell):\n",
    "    return(pd.Series(hog(row.iloc[1:].to_numpy().reshape(28,28,1), orientations=ori, pixels_per_cell=(cell, cell), cells_per_block=(1,1),multichannel=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T14:03:31.178720Z",
     "start_time": "2021-11-23T14:03:29.414309Z"
    }
   },
   "outputs": [],
   "source": [
    "hog_train = data_train.apply(my_hog, axis=1, args=(8,14))\n",
    "hog_test = data_test.apply(my_hog, axis=1, args=(8,14))\n",
    "hog_train['label'] = data_train.label\n",
    "hog_test['label'] = data_test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Todo:**</font> Try different random forests (by considering different number of trees) on this new dataset and select the most appropriated one.\n",
    "\n",
    "\n",
    "<font color=\"red\">**Question 2:**</font> \n",
    "What is the estimation of the generalization error of random forest for this dataset ? Conclusion ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T14:03:54.572814Z",
     "start_time": "2021-11-23T14:03:49.150224Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO - select the appropriate RandomForestClassifier on the HOG features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T14:04:11.340284Z",
     "start_time": "2021-11-23T14:04:10.840174Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO - Compute the real error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#1E90FF\">Exercise 3. A small tour to Adaboost</font>\n",
    "\n",
    "<code>AdaBoostClassifier</code> implements the popular boosting algorithm AdaBoost. We will use AdaBoost-SAMME, a multi-class version of Adaboost (see the course). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df=pd.read_csv('./data/data_exam.txt', sep=' ')\n",
    "df.head()\n",
    "dataset = df.rename(columns={df.columns[0]: 'X1',df.columns[1]: 'X2',df.columns[2]: 'Y'})\n",
    "sns.scatterplot(data=dataset, x='X1', y='X2', hue='Y', marker='+', palette=['blue','red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn an AdaBoost classifier\n",
    "data_train, data_test = train_test_split(dataset, test_size = 0.3, random_state = 6)\n",
    "aboost = AdaBoostClassifier(n_estimators=5, algorithm=\"SAMME\", random_state=0)\n",
    "aboost.fit(data_train.loc[:, ['X1', 'X2']], data_train.Y)\n",
    "aboost.score(data_test.loc[:, ['X1', 'X2']], data_test.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Estimator used to grow the ensemble : \", aboost.base_estimator_)\n",
    "print(\"Weights for each estimator in the boosted ensemble : \", aboost.estimator_weights_)\n",
    "print(\"Classification error for each estimator in the boosted ensemble : \", aboost.estimator_errors_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Question 1:**</font> \n",
    "- What is the weak classifier used here?\n",
    "- How many iterations are done?\n",
    "\n",
    "<font color=\"red\">**Question 2:**</font> \n",
    "- Remind how the estimator weights are computed? (Give the formula. Be careful, this is the SAMME version)\n",
    "\n",
    "<font color=\"blue\">**Todo:**</font> Apply the formula to retrieve the estimator weights (at least one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - retrieve the estimator weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_decision_boundaries(model, data):\n",
    "    h = 0.05\n",
    "    xx, yy = np.meshgrid(\n",
    "            np.linspace(data.iloc[:, 0].min(), data.iloc[:, 0].max()),\n",
    "            np.linspace(data.iloc[:, 1].min(), data.iloc[:, 1].max()))\n",
    "    zz = np.c_[xx.ravel(), yy.ravel()]\n",
    "    zz = pd.DataFrame(zz)\n",
    "    zz2 = zz\n",
    "    zz2.columns=['X1','X2'] # avoid warning on valid feature names\n",
    "    pred_zz= pd.Series(model.predict(zz2))\n",
    "    color_map = matplotlib.colors.ListedColormap(pd.Series(['blue', 'red']))\n",
    "    fig = plt.figure(figsize=  (8,8))\n",
    "    fig = plt.scatter(zz.iloc[:,0], zz.iloc[:,1], c = pred_zz, cmap = color_map, marker='+', s=70)\n",
    "    fig = plt.scatter(data.iloc[:,0], data.iloc[:,1], s = 50, c = data.iloc[:,2], cmap = color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_decision_boundaries(aboost,data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Todo:**</font> Compare with a decision tree: performances, decision boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - compare with decision tree and draw the decision boundaries\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
